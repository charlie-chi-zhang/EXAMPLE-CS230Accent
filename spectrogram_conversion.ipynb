{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "from librosa import display\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to parse out audio from clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Function that parse audio from audio clip\n",
    "# Input: wav file name, t1 (start of phoeme), t2 (end of phoeme)\n",
    "# Returns: audio segments of individual phoeme between t1 and t2\n",
    "\"\"\"\n",
    "def parse_out_segment(audio_clip, t1, t2):\n",
    "    \n",
    "    # Grab audio segment between t1 and t2\n",
    "    # First grab the first t2 milliseconds\n",
    "    first_audio_segment = audio_clip[:t2]\n",
    "    \n",
    "    # Then grab the last t2-t1 milliseconds\n",
    "    phoeme_length = t2 - t1\n",
    "    audio_segment = first_audio_segment[-phoeme_length:]\n",
    "    \n",
    "    return audio_segment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to change volume (magnitude) of audio clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Function tha changes the volume (magnitude) of the audio clip\n",
    "# Input: pydub audio clip\n",
    "# Returns: audio increased and decreased\n",
    "\"\"\"\n",
    "def volume_change_audio_clip(audio_clip):\n",
    "    \n",
    "    db_shift = 10\n",
    "    \n",
    "    # boost volume by 10dB\n",
    "    louder_audio = audio_clip + db_shift\n",
    "\n",
    "    # reduce volume by 10dB\n",
    "    quieter_audio = audio_clip - db_shift\n",
    "    \n",
    "    return louder_audio,quieter_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to segment the audio clip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has flags to shift the audio by 250ms and change volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Function that segments audio clip into smaller segments\n",
    "# Input: wav file name, flag to shift by 250ms, flag to change volume\n",
    "# Returns: dictionary of audio segments\n",
    "\"\"\"\n",
    "def segment_audio_clip(audio_file_name, wav_name, shift_250ms, flag_change_volume):\n",
    "    \n",
    "    # Length is 1000ms = 1sec\n",
    "    segment_length = 500\n",
    "    shift_length = shift_250ms\n",
    "    \n",
    "    # Read the audio file\n",
    "    audio_clip = AudioSegment.from_wav(audio_file_name)\n",
    "    #print audio_clip.duration_seconds\n",
    "    \n",
    "    # Calculate the number of segments based on audio clip duration and segment length\n",
    "    audio_duration_ms = (audio_clip.duration_seconds)*1000    \n",
    "    num_segments = int(audio_duration_ms / segment_length)\n",
    "    #print num_segments\n",
    "    \n",
    "    # Segment the audio clip and save in dictionary\n",
    "    segment_dict = {}\n",
    "    \n",
    "    for i in range(num_segments):\n",
    "        key = wav_name + '_' + str(i)\n",
    "        segment_audio = parse_out_segment(audio_clip, i*1000, i*1000+segment_length)\n",
    "        segment_dict[key] = segment_audio\n",
    "        \n",
    "        # Check if volume change is request\n",
    "        if (flag_change_volume):\n",
    "            louder_audio_seg, quieter_audio_seg = volume_change_audio_clip(segment_audio)\n",
    "            segment_dict[key + '_louder'] = louder_audio_seg\n",
    "            segment_dict[key + '_quieter'] = quieter_audio_seg\n",
    "    \n",
    "        \n",
    "    # Cut out the first 250ms of the audio clip\n",
    "    if (shift_250ms):        \n",
    "        new_audio_duration_ms = audio_duration_ms - shift_length\n",
    "        num_segments = int(new_audio_duration_ms / segment_length)\n",
    "        \n",
    "        wav_name = split_wav_file_name[0] + '_shifted'\n",
    "    \n",
    "        for i in range(num_segments):\n",
    "            key = wav_name + '_' + str(i)\n",
    "            segment_audio = parse_out_segment(audio_clip, i*1000, i*1000+segment_length)\n",
    "            segment_dict[key] = segment_audio\n",
    "            \n",
    "            # Check if volume change is request\n",
    "            if (flag_change_volume):\n",
    "                louder_audio_seg, quieter_audio_seg = volume_change_audio_clip(segment_audio)\n",
    "                segment_dict[key + '_louder'] = louder_audio_seg\n",
    "                segment_dict[key + '_quieter'] = quieter_audio_seg\n",
    "    \n",
    "    return segment_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to export audio segment to individual WAV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Function that exports each audio segment to individual WAV files\n",
    "# Input: dictionary of phoemes audio clips\n",
    "# Returns: nothing\n",
    "\"\"\"\n",
    "def export_audio_segments(audio_segments_dict, wav_file_name, accent_id):\n",
    "    \n",
    "    for timestamp in audio_segments_dict:\n",
    "        export_file_name = accent_id + '_spectrograms\\\\' + timestamp + '.wav'\n",
    "        #export_file_name = timestamp + '.wav'\n",
    "        \n",
    "        #Exports to a wav file\n",
    "        audio_segment = audio_segments_dict[timestamp]\n",
    "        audio_segment.export(export_file_name, format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to change the pitch of the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Function that changes the pitch of given audio\n",
    "# Input: Librosa audio data\n",
    "# Returns: audio pitch shifted up and pitch shifted down\n",
    "\"\"\"\n",
    "def pitch_shift_audio(librosa_samples, sampling_rate):\n",
    "    # Shift up by a major third (four half-steps)\n",
    "    samples_third = librosa.effects.pitch_shift(librosa_samples, sampling_rate, n_steps=4)\n",
    "    \n",
    "    # Shift down by a tritone (six half-steps)\n",
    "    samples_tritone = librosa.effects.pitch_shift(librosa_samples, sampling_rate, n_steps=-6)\n",
    "    \n",
    "    return samples_third, samples_tritone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create spectrograms of each WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Function that creates spectrogram of each WAV file\n",
    "# Input: none\n",
    "# Returns: nothing\n",
    "\"\"\"\n",
    "def convert_audio_to_spectrograms(accent_id, flag_pitch_shift):\n",
    "    reg_ex = accent_id + '_spectrograms\\*.wav'\n",
    "    wav_file_list = glob.glob(reg_ex)\n",
    "    #print wav_file_list\n",
    "    \n",
    "    spectrogram_list = []\n",
    "    \n",
    "    for wav_file in wav_file_list:\n",
    "        #print wav_file\n",
    "        \n",
    "        # Convert wav file to spectrogram (FFT)\n",
    "        samples, sampling_rate = librosa.load(wav_file)\n",
    "        print \"Sample rate = \" + str(sampling_rate)\n",
    "        \n",
    "        # Comput STFT of the audio\n",
    "        D = librosa.stft(samples)\n",
    "            \n",
    "        D_magnitude = np.abs(D)\n",
    "        print (D_magnitude).shape\n",
    "        \n",
    "        D_reshape = np.reshape(D_magnitude,(205,110))\n",
    "        #print D_reshape.shape\n",
    "        \n",
    "        # Append to spectrogram list\n",
    "        spectrogram_list.append(D_reshape)\n",
    "        \n",
    "        # Check if pitch shifting is requested\n",
    "        if (flag_pitch_shift):\n",
    "            pitched_up_samples, pitched_down_samples = pitch_shift_audio(samples, sampling_rate)\n",
    "            \n",
    "            # Compute STFT\n",
    "            D_pitched_up = librosa.stft(pitched_up_samples)\n",
    "            D_pitched_down = librosa.stft(pitched_down_samples)\n",
    "            \n",
    "            # Reshape\n",
    "            D_pitched_up_reshape = np.reshape(np.abs(D_pitched_up),(205,110))\n",
    "            D_pitched_down_reshape = np.reshape(np.abs(D_pitched_down),(205,110))\n",
    "            \n",
    "            # Append to spectrogram list\n",
    "            spectrogram_list.append(D_pitched_up_reshape)\n",
    "            spectrogram_list.append(D_pitched_down_reshape)\n",
    "        \n",
    "        # Plot the spectrom\n",
    "        D_amp_to_db = librosa.amplitude_to_db(D_magnitude, ref=np.max)\n",
    "        plt.pcolormesh(D_amp_to_db)\n",
    "        librosa.display.specshow(D_amp_to_db, y_axis='log', x_axis='time')\n",
    "        \"\"\"\n",
    "        # Find clip name\n",
    "        split_str = accent_id + '_spectrograms\\\\'\n",
    "        split_file_name = wav_file.split(split_str)\n",
    "        wav_file_name = split_file_name[len(split_file_name)-1]\n",
    "        split_wav_file = wav_file_name.split('.wav')\n",
    "        wav_clip_name = split_wav_file[0]\n",
    "        \n",
    "        plot_title_str = 'Power spectrogram of ' + accent_id + ' ' + wav_clip_name\n",
    "        plt.title(plot_title_str)\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \"\"\"\n",
    "        \n",
    "        # Plot spectrogram of pitch shifted audio\n",
    "        if (flag_pitch_shift):\n",
    "            D_amp_to_db = librosa.amplitude_to_db(np.abs(D_pitched_up), ref=np.max)\n",
    "            plt.pcolormesh(D_amp_to_db)\n",
    "            librosa.display.specshow(D_amp_to_db, y_axis='log', x_axis='time')\n",
    "            \"\"\"\n",
    "            plot_title_str = 'Power spectrogram of ' + accent_id + ' ' + wav_clip_name + ' pitched UP'\n",
    "            plt.title(plot_title_str)\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            D_amp_to_db = librosa.amplitude_to_db(np.abs(D_pitched_down), ref=np.max)\n",
    "            plt.pcolormesh(D_amp_to_db)\n",
    "            librosa.display.specshow(D_amp_to_db, y_axis='log', x_axis='time')\n",
    "                    \n",
    "            plot_title_str = 'Power spectrogram of ' + accent_id + ' ' + wav_clip_name + ' pitched DOWN'\n",
    "            plt.title(plot_title_str)\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \"\"\"\n",
    "    return spectrogram_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../dataset/cmu_us_bdl_arctic/wav/arctic_a0002.wav']\n",
      "['../dataset/cmu_us_bdl_arctic', 'arctic_a0002.wav']\n",
      "Sample rate = 22050\n",
      "(1025L, 22L)\n",
      "Sample rate = 22050\n",
      "(1025L, 22L)\n",
      "Sample rate = 22050\n",
      "(1025L, 22L)\n",
      "Sample rate = 22050\n",
      "(1025L, 22L)\n",
      "Sample rate = 22050\n",
      "(1025L, 22L)\n",
      "Sample rate = 22050\n",
      "(1025L, 22L)\n",
      "bdl(6L, 205L, 110L)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# MAIN FUNCTION\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Grab all the audio clip files\n",
    "    #accent_id_list = ['bdl','aew','rms','clb','eey','ljm','lnh','slt','ahw','awb','fem','jmk','rxr','axb','slp','aup','gka','ksp']\n",
    "    accent_id_list = ['bdl']\n",
    "    for accent_id in accent_id_list:\n",
    "        cmd_arg = '../dataset/cmu_us_' + accent_id + '_arctic/wav/arctic_a0002.wav'\n",
    "        clip_file_list = glob.glob(cmd_arg)\n",
    "\n",
    "        print clip_file_list\n",
    "\n",
    "        #--------------------------------------------------\n",
    "        # Split audio into segments\n",
    "        #--------------------------------------------------\n",
    "        for wav_file in clip_file_list:\n",
    "            #print wav_file\n",
    "            \n",
    "            #--------------------------------------------------\n",
    "            # WAV NAME & NUMBER\n",
    "            #--------------------------------------------------\n",
    "            split_wav_file = wav_file.split('/wav/')\n",
    "            print str(split_wav_file)\n",
    "            split_wav_file_name = split_wav_file[1].split('.wav')\n",
    "            wav_name = split_wav_file_name[0]\n",
    "            \n",
    "            #--------------------------------------------------\n",
    "            # SEGMENT WAV FILE\n",
    "            #--------------------------------------------------\n",
    "            audio_segments_dict = segment_audio_clip(wav_file, wav_name, shift_250ms=False, flag_change_volume=False)\n",
    "            #print audio_segments_dict\n",
    "\n",
    "            #--------------------------------------------------\n",
    "            # EXPORT AS WAV FILES\n",
    "            #--------------------------------------------------\n",
    "            export_audio_segments(audio_segments_dict, wav_name, accent_id)\n",
    "\n",
    "        #--------------------------------------------------\n",
    "        # CONVERT TO SPECTROGRAM\n",
    "        #--------------------------------------------------\n",
    "        spectrogram_list = convert_audio_to_spectrograms(accent_id, flag_pitch_shift=False)\n",
    "        spectrogram_array = np.array(spectrogram_list)\n",
    "        print accent_id + str(spectrogram_array.shape)\n",
    "\n",
    "        #--------------------------------------------------\n",
    "        # PRINT OUT SPECTROGRAM TO FILE\n",
    "        #--------------------------------------------------\n",
    "        spectrogram_file_name = accent_id + '_spectrogram_array.npy'\n",
    "        np.save(spectrogram_file_name, spectrogram_array)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
